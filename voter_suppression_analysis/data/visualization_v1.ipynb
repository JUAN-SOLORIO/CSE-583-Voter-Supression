{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import re\n",
    "'''\n",
    "Code to load, clean, and combine all relevant data.\n",
    "See README for references re: data.\n",
    "'''\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "#############\n",
    "# CONSTANTS #\n",
    "#############\n",
    "\n",
    "\n",
    "# useful constants for accessing files\n",
    "AGE_PATH_REGEX = 'clean/*_age.csv'\n",
    "SEX_PATH_REGEX = 'clean/*_sexrace.csv'\n",
    "LAWS_DATA_PATH = 'clean/supression.csv'\n",
    "\n",
    "# useful constants for renaming and removing columns\n",
    "AGE_COLUMN_NAMES = [\n",
    "    'state', 'age_bracket', 'total', 'total_reg', 'percent_reg',\n",
    "    'ci_reg', 'total_voted', 'percent_voted', 'ci_voted', 'yr'\n",
    "]\n",
    "\n",
    "SEX_COLUMN_NAMES = [\n",
    "    'state', 'group', 'pop', 'total_cit', 'percent_cit', 'ci_cit',\n",
    "    'total_reg', 'percent_reg', 'ci_reg', 'total_voted', 'percent_voted',\n",
    "    'ci_voted', 'yr'\n",
    "]\n",
    "\n",
    "KEEP_AGE_COLUMNS = [\n",
    "    'state', 'age_bracket', 'total', 'total_reg', 'total_voted', \n",
    "    'percent_reg', 'percent_voted', 'yr'\n",
    "]\n",
    "\n",
    "KEEP_SEX_COLUMNS = ['state', 'group', 'total_cit', 'total_reg', 'total_voted', 'yr']\n",
    "\n",
    "# useful constants for standardizing state labels \n",
    "STATE_NAMES = ['ALABAMA', 'ALASKA', 'ARIZONA', 'ARKANSAS', 'CALIFORNIA', \n",
    "    'COLORADO', 'CONNECTICUT', 'DELAWARE', 'DISTRICT OF COLUMBIA', 'FLORIDA', \n",
    "    'GEORGIA', 'HAWAII', 'IDAHO', 'ILLINOIS', 'INDIANA', 'IOWA', 'KANSAS', \n",
    "    'KENTUCKY', 'LOUISIANA', 'MAINE', 'MARYLAND', 'MASSACHUSETTS', \n",
    "    'MICHIGAN', 'MINNESOTA', 'MISSISSIPPI', 'MISSOURI', 'MONTANA', 'NEBRASKA', \n",
    "    'NEVADA', 'NEW HAMPSHIRE', 'NEW JERSEY', 'NEW MEXICO', 'NEW YORK',\n",
    "    'NORTH CAROLINA', 'NORTH DAKOTA', 'OHIO', 'OKLAHOMA', 'OREGON',\n",
    "    'PENNSYLVANIA', 'RHODE ISLAND', 'SOUTH CAROLINA', 'SOUTH DAKOTA',\n",
    "    'TENNESSEE', 'TEXAS', 'UTAH', 'VERMONT', 'VIRGINIA', 'WASHINGTON',\n",
    "    'WEST VIRGINIA', 'WISCONSIN', 'WYOMING'\n",
    "]\n",
    "\n",
    "# note these integers are related to US Census Bureau ordering \n",
    "STATE_NUMS = [1,  2,  4,  5,  6,  8,  9, 10, 11, 12, 13, 15, 16, 17, 18, 19, \n",
    "    20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37,\n",
    "    38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56,\n",
    "]\n",
    "\n",
    "STATES_TABLE = list(zip(STATE_NAMES, STATE_NUMS))\n",
    "\n",
    "\n",
    "#############\n",
    "# FUNCTIONS #\n",
    "#############\n",
    "\n",
    "\n",
    "def get_age_df(file_path):\n",
    "    '''\n",
    "    Load age data by file name, transform into pd.DataFrame and\n",
    "    return DataFrame object with only relevant columns and cleaned\n",
    "    values.\n",
    "\n",
    "    Note: NaN values are kept for possible use in modeling/viz.\n",
    "\n",
    "    Args:\n",
    "        file_path: str, designating file to retrieve for a given year\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame, processed age data for that year\n",
    "    '''\n",
    "\n",
    "    # access, label, and sanitize data\n",
    "    df = pd.read_csv(file_path, header=0, names=AGE_COLUMN_NAMES)\n",
    "    df = df[KEEP_AGE_COLUMNS]\n",
    "    df.state = df.state.str.upper()\n",
    "    df.yr = df.yr.astype(str)\n",
    "    df.total = df.total.replace(',','', regex=True).apply(pd.to_numeric, errors='coerce')\n",
    "    df.total_reg = df.total_reg.replace(',','', regex=True).apply(pd.to_numeric, errors='coerce')\n",
    "    df.total_voted = df.total_voted.replace(',','', regex=True).apply(pd.to_numeric, errors='coerce')\n",
    "    df.age_bracket = df.age_bracket.map(lambda x: x.lstrip('.'))\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_sexrace_df(file_path):\n",
    "    '''\n",
    "    Load sexrace data by file name, transform into pd.DataFrame\n",
    "    and return DataFrame object with only relevant columns and cleaned\n",
    "    values.\n",
    "\n",
    "    Note: NaN values are kept for possible use in modeling/viz.\n",
    "\n",
    "    Args:\n",
    "        file_path: str, file for which to retrieve sexrace data\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame, processed sexrace data for that year\n",
    "    '''\n",
    "\n",
    "    # access, label, and sanitize data\n",
    "    df = pd.read_csv(file_path, header=0, names=SEX_COLUMN_NAMES)\n",
    "    df = df[KEEP_SEX_COLUMNS]\n",
    "    df.state = df.state.str.upper()\n",
    "    df.yr = df.yr.astype(str)\n",
    "    df.total_cit = df.total_cit.replace(',','', regex=True).apply(pd.to_numeric, errors='coerce')\n",
    "    df.total_reg = df.total_reg.replace(',','', regex=True).apply(pd.to_numeric, errors='coerce')\n",
    "    df.total_voted = df.total_voted.replace(',','', regex=True).apply(pd.to_numeric, errors='coerce')\n",
    "    df.group = df.group.map(lambda x: x.lstrip('.'))\n",
    "    return df\n",
    "\n",
    "\n",
    "def combine_age_data():\n",
    "    '''\n",
    "    Retrieve all age-related data files, combine into one pd.DataFrame\n",
    "    object, and attach legislative data columns.\n",
    "\n",
    "    Args:   None\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame, combined age data for all years\n",
    "    '''\n",
    "\n",
    "    # retrieve all relevant file paths\n",
    "    age_file_paths = glob.glob(AGE_PATH_REGEX)\n",
    "    df_list = []\n",
    "\n",
    "    # iterative store pd.DataFrame representation of each\n",
    "    for age_file in age_file_paths:\n",
    "        print('Reading %s...' % age_file)\n",
    "        df = get_age_df(age_file)\n",
    "        df_list.append(df)\n",
    "\n",
    "    # concatenate and attach legislative data\n",
    "    combined = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "    laws_df = pd.read_csv(LAWS_DATA_PATH)\n",
    "    laws_df.STATE = laws_df.STATE.str.upper()\n",
    "\n",
    "    result_df = combined.merge(laws_df,\n",
    "                               how='outer',\n",
    "                               left_on='state',\n",
    "                               right_on='state')\n",
    "    \n",
    "    # make nationwide labels consistent and finish \n",
    "    result_df.state.loc[result_df.state == 'US'] = 'NATIONAL'\n",
    "    result_df.state.loc[result_df.state == 'UNITED STATES'] = 'NATIONAL'\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def combine_sexrace_data():\n",
    "    '''\n",
    "    Retrieve all sexrace-related data files, combine into one\n",
    "    pd.DataFrame object, and attach legislative data columns.\n",
    "\n",
    "    Args:   None\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame, combined sexrace data for all years\n",
    "    '''\n",
    "\n",
    "    # retrieve all relevant file paths\n",
    "    sex_file_paths = glob.glob(SEX_PATH_REGEX)\n",
    "    df_list = []\n",
    "\n",
    "    # iterative store pd.DataFrame representation of each\n",
    "    for sex_file in sex_file_paths:\n",
    "        print('Reading %s...' % sex_file)\n",
    "        df = get_sexrace_df(sex_file)\n",
    "        df_list.append(df)\n",
    "\n",
    "    # concatenate and attach legislative data\n",
    "    combined = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "    laws_df = pd.read_csv(LAWS_DATA_PATH)\n",
    "    laws_df.STATE = laws_df.STATE.str.upper()\n",
    "\n",
    "    result_df = combined.merge(laws_df,\n",
    "                               how='outer',\n",
    "                               left_on='state',\n",
    "                               right_on='state')\n",
    "    \n",
    "    # make nationwide labels consistent and finish \n",
    "    result_df.state.loc[result_df.state == 'US'] = 'NATIONAL'\n",
    "    result_df.state.loc[result_df.state == 'UNITED STATES'] = 'NATIONAL'\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def homogenize_age_data(df_in):\n",
    "    \"\"\"\n",
    "    Structures the age data by creating the desired age groups\n",
    "    of 'Total','18 to 44', '45 to 65', '65+' into a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df_in: Dataframe created by function combine_age_data()\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame, age bracket structured data for all years\n",
    "    \"\"\"\n",
    "    df_states = pd.DataFrame(STATES_TABLE, columns=['state', 'id'])\n",
    "    df_states.state = df_states.state.str.capitalize()\n",
    "\n",
    "    # splitting inconsistent age brackets into many DFs\n",
    "    df = df_in.copy()\n",
    "    df_65plus = df.loc[(df.age_bracket == '65 to 74')\n",
    "        | (df.age_bracket == '75+')\n",
    "        | (df.age_bracket == '65 to 75')\n",
    "        | (df.age_bracket == '65+'),\n",
    "    ]\n",
    "\n",
    "    df_45_64 = df.loc[(df.age_bracket == '45 to 64')\n",
    "        | (df.age_bracket == '45 to 55')\n",
    "        | (df.age_bracket == '55 to 65')\n",
    "        | (df.age_bracket == '45 to 65'),\n",
    "    ]\n",
    "\n",
    "    df_18_44 = df.loc[(df.age_bracket == '18 to 24')\n",
    "        | (df.age_bracket == '18 to 25')\n",
    "        | (df.age_bracket == '25 to 44')\n",
    "        | (df.age_bracket == '25 to 35')\n",
    "        | (df.age_bracket == '35 to 45')\n",
    "        | (df.age_bracket == '25 to 45')\n",
    "        | (df.age_bracket == '25 to 34')\n",
    "        | (df.age_bracket == '35 to 44'),\n",
    "    ]\n",
    "\n",
    "    df_total = df.loc[df.age_bracket == 'Total',]\n",
    "\n",
    "    # iteratively group these DFs by state and year\n",
    "    df_list = [df_total, df_18_44, df_45_64, df_65plus]\n",
    "    age_brackets = ['Total','18 to 44', '45 to 65', '65+']\n",
    "    result = []\n",
    "\n",
    "    for i, df in enumerate(df_list):\n",
    "        df = df.groupby(['state', 'yr'], sort=False).sum().reset_index()\n",
    "        df['age_bracket'] = age_brackets[i]\n",
    "        result.append(df)\n",
    "\n",
    "    # recombine all age bracket DFs\n",
    "    result = pd.concat(result, axis=0, ignore_index=True)\n",
    "    result.sort_values(['yr', 'state'], inplace=True)\n",
    "\n",
    "    # compute voter turnout metric\n",
    "    result['percent_reg'] = result.total_reg / result.total\n",
    "    result['percent_voted'] = result.total_voted / result.total\n",
    "\n",
    "    # refomatting\n",
    "    result.yr = result.yr.astype(int)\n",
    "    result.state = result.state.str.capitalize()\n",
    "    result = result.rename(columns={'age_bracket':'group'})\n",
    "\n",
    "    # attach our state labels/IDs and finish\n",
    "    result = pd.merge(result, df_states, left_on='state', right_on='state')\n",
    "    return result\n",
    "\n",
    "\n",
    "def homogenize_sexrace_data(df_in):\n",
    "    \"\"\"\n",
    "    Structures the age data by creating the desired age groups\n",
    "    of 'Total','18 to 44', '45 to 65', '65+' into a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df_in: Dataframe created by function combine_age_data()\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame, age bracket structured data for all years\n",
    "    \"\"\"\n",
    "    df_states = pd.DataFrame(STATES_TABLE, columns=['state', 'id'])\n",
    "    df_states.state = df_states.state.str.capitalize()\n",
    "    \n",
    "    # useful constants for renaming relevant demographic groups\n",
    "    ORIGINAL_GROUPS = ['Total', 'Male', 'Female', 'N-H White','N-H Black',\n",
    "                       'API', 'Hispanic', 'Non-Hispanic White', 'Non-Hispanic Black',\n",
    "                       'Asian and Pacific Islander','White non-Hispanic alone',\n",
    "                       'Black alone', 'Asian alone','Hispanic (of any race)']\n",
    "    RENAME_GROUPS = ['Total', 'Male', 'Female', 'White', 'Black',\n",
    "                     'Asian & Pacific Islander','Hispanic', 'White',\n",
    "                     'Black', 'Asian & Pacific Islander','White','Black',\n",
    "                     'Asian & Pacific Islander','Hispanic']\n",
    "    \n",
    "    # useful constants for the 'total's columns to work with\n",
    "    TOTALS_COLUMNS = ['total_cit', 'total_reg', 'total_voted']\n",
    "\n",
    "    # interatively renaming demographic groups\n",
    "    df = df_in.copy()\n",
    "    for (og, rm) in zip(ORIGINAL_GROUPS, RENAME_GROUPS):\n",
    "        df.group.loc[df.group == og] = rm\n",
    "\n",
    "    # keeping relevant groups and setting years as str\n",
    "    df_groups_kept = df.loc[df.group.isin(RENAME_GROUPS)]\n",
    "    df_groups_kept.yr = df_groups_kept.yr.astype(float).astype(int).astype(str)\n",
    "\n",
    "    # interatively validating the 'total's values \n",
    "    for col in TOTALS_COLUMNS:\n",
    "        df_temp = df_groups_kept.pivot_table(index=['state','yr'], columns='group', values=col)\n",
    "        df_temp = df_temp.reset_index()\n",
    "        totals = df_temp[['Male', 'Female']].sum(axis=1)\n",
    "        df_temp.Total = totals\n",
    "        df_temp_unpivot = df_temp.melt(id_vars=['state','yr'], value_name=col)\n",
    "        if col == 'total_cit':\n",
    "            df_merge = df_temp_unpivot.copy()\n",
    "        else:\n",
    "            next\n",
    "        df_merge = pd.merge(df_merge, df_temp_unpivot, how='left',\n",
    "                           left_on=['state', 'yr', 'group'], right_on=['state', 'yr', 'group'])\n",
    "\n",
    "    laws_df = pd.read_csv(LAWS_DATA_PATH)\n",
    "    laws_df.state = laws_df.state.str.upper()\n",
    "\n",
    "    results = df_merge.merge(laws_df,\n",
    "                               how='outer',\n",
    "                               left_on='state',\n",
    "                               right_on='state')\n",
    "    # reformating values and column names\n",
    "    df_merge_kept = results.drop('total_cit_y', axis=1)\n",
    "    df_merge_kept.state = df_merge_kept.state.str.capitalize()\n",
    "    df_demo_out = df_merge_kept.rename(columns={\"total_cit_x\":'total'})\n",
    "    df_demo_out = df_demo_out.sort_values(by=['yr', 'state']).round()\n",
    "    df_demo_out.yr = df_demo_out.yr.astype(int)\n",
    "    \n",
    "    # calculating the percentage of voter turnout totals\n",
    "    df_demo_out['percent_reg'] = df_demo_out.total_reg / df_demo_out.total\n",
    "    df_demo_out['percent_voted'] = df_demo_out.total_voted / df_demo_out.total\n",
    "        \n",
    "    # attach our state labels/IDs and finish\n",
    "    df_demo_out = pd.merge(df_demo_out, df_states, left_on='state', right_on='state')\n",
    "    \n",
    "    return df_demo_out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_json_shape(url='https://eric.clst.org/assets/wiki/uploads/Stuff/gz_2010_us_040_00_5m.json'):\n",
    "    \"\"\"\n",
    "    Download the json data from the given url link. Specific to US continental geoshapes.\n",
    "    \n",
    "    Args:\n",
    "        url (optional): url link to json file\n",
    "    Returns:\n",
    "        json structure\n",
    "    \"\"\"\n",
    "    req = requests.get(url)\n",
    "    return req.json()\n",
    "\n",
    "def create_geodataframe(df_in):\n",
    "    \"\"\"\n",
    "    Creates a GeoPandas dataframe with the geo location and shapes\n",
    "    of US States merged with the povided datafram of state data.\n",
    "    \n",
    "    Args:\n",
    "        df_in: pandas dataframe, must have 'state' column for US States\n",
    "    Returns:\n",
    "        Geopandas dataframe\n",
    "    \"\"\"\n",
    "    # get the shape of the states\n",
    "    states_json = get_json_shape()\n",
    "\n",
    "    # set Geopandas dataframe\n",
    "    gpd_states = gpd.GeoDataFrame.from_features(states_json)\n",
    "\n",
    "    # make names of states all uppper case\n",
    "    gpd_states['NAME'] = gpd_states['NAME'].str.upper()\n",
    "\n",
    "    gpd_states['centroid_lon'] = gpd_states['geometry'].centroid.x\n",
    "    gpd_states['centroid_lat'] = gpd_states['geometry'].centroid.y\n",
    "    \n",
    "    # merge states data and states geopandas dfs\n",
    "    gpd_states.NAME = gpd_states.NAME.str.capitalize()\n",
    "    states_merged = pd.merge(df_in, gpd_states, left_on='state', right_on='NAME')\n",
    "    \n",
    "    # convert to GeoPandas Dataframe\n",
    "    gpd_merged = gpd.GeoDataFrame(states_merged)\n",
    "    return gpd_merged\n",
    "\n",
    "def to_geojson(gpd_df_in):\n",
    "    \"\"\"\n",
    "    Converts GeoPandas dataframe to GeoJson to be used in Altair Viz\n",
    "    \n",
    "    Args:\n",
    "        gpd_df_in: GeoPandas dataframe\n",
    "    Returns:\n",
    "        Altair json data structure\n",
    "    \"\"\"\n",
    "    #convert back to GeoJson to plot in altair\n",
    "    choro_json = json.loads(gpd_df_in.to_json())\n",
    "    choro_data = alt.Data(values=choro_json['features'])\n",
    "    return choro_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# A dropdown filter\n",
    "categories_age = ['Total', '18 to 44', '45 to 65', '65+']\n",
    "catage_dropdown = alt.binding_select(options=categories_age)\n",
    "cat_select_age = alt.selection_single(fields=['group'],\n",
    "                                  bind=catage_dropdown,\n",
    "                                  name=\"Demographic\",\n",
    "                                  init={'group':'Total'})\n",
    "categories_demo = ['Total', 'Male', 'Female', 'White', 'Black',\n",
    "                     'Asian & Pacific Islander','Hispanic']\n",
    "catdemo_dropdown = alt.binding_select(options=categories_demo)\n",
    "cat_select_demo = alt.selection_single(fields=['group'],\n",
    "                                  bind=catdemo_dropdown,\n",
    "                                  name=\"Demographic\",\n",
    "                                  init={'group':'Total'})\n",
    "\n",
    "\n",
    "# A slider filter\n",
    "slider = alt.binding_range(min=2000, max=2018, step=2, name='Election Year')\n",
    "select_yr = alt.selection_single(name='SelectorName', fields=['yr'],\n",
    "                                   bind=slider, init={'yr': 2000})\n",
    "\n",
    "\n",
    "\n",
    "def us_map_chart(df_in, map_value, map_title,selection_link=select_yr):\n",
    "    df = df_in.copy()\n",
    "    PIVOT_COLUMNS = ['state','id','group','yr']\n",
    "    columns_keep = PIVOT_COLUMNS + [map_value]\n",
    "    year_columns = [str(year) for year in range(2000, 2019, 2)]\n",
    "    \n",
    "    df_pivot = df[columns_keep].pivot_table(index=['id','state','group'], \n",
    "                                                                             columns='yr', values=map_value)\n",
    "    mapdf = df_pivot.reset_index()\n",
    "    mapdf.columns = mapdf.columns.astype(str)\n",
    "    \n",
    "    states = alt.topo_feature(data.us_10m.url, 'states')\n",
    "    states['url'] = 'https://raw.githubusercontent.com/vega/vega/master/docs/data/us-10m.json'\n",
    "\n",
    "    map_chart=alt.Chart(states).mark_geoshape(\n",
    "    stroke='black',\n",
    "    strokeWidth=0.05\n",
    "    ).project(\n",
    "        type='albersUsa'\n",
    "    ).transform_lookup(\n",
    "        lookup='id',\n",
    "        from_=alt.LookupData(mapdf.loc[mapdf.group=='Total'], 'id', ['state']+year_columns)\n",
    "    ).transform_fold(\n",
    "        year_columns, as_=['yr', 'Percent']\n",
    "    ).transform_calculate(\n",
    "        yr='parseInt(datum.yr)',\n",
    "        Percent='isValid(datum.Percent) ? datum.Percent : -1'  \n",
    "    ).encode(\n",
    "        tooltip=['state:N','Percent:Q'],\n",
    "        color = alt.condition(\n",
    "            'datum.Percent > 0',\n",
    "            alt.Color('Percent:Q', scale=alt.Scale(domain=[0.2,.9],scheme='yellowgreenblue', type='linear')),\n",
    "            alt.value('#dbe9f6')\n",
    "        )).add_selection(\n",
    "        selection_link\n",
    "    ).properties(\n",
    "        title=map_title,\n",
    "        width=300,\n",
    "        height=200\n",
    "    ).transform_filter(\n",
    "        selection_link\n",
    "    )\n",
    "    \n",
    "    return map_chart\n",
    "\n",
    "def scatter_turnout(df_in, x_value, y_value, color_variable, title, x_title, y_title,\n",
    "                    select_slider, select_dropdown):\n",
    "    \n",
    "    # A selection for interval highlighing on charts\n",
    "    highlight = alt.selection_interval(encodings=['x'])\n",
    "    color = alt.Color(color_variable)\n",
    "    click = alt.selection_multi(encodings=['color'])\n",
    "    \n",
    "    df = df_in.copy()\n",
    "    \n",
    "    scatter = alt.Chart().mark_point().encode(\n",
    "        x=alt.X(x_value, title=x_title,\n",
    "               scale=alt.Scale(domain=[.15, .96])),\n",
    "        y=alt.Y(y_value, title=y_title,\n",
    "               scale=alt.Scale(domain=[.15, .93])),\n",
    "        size=alt.Size('total:Q', title='Total Eligible Voters'),\n",
    "        color=alt.condition(highlight, color_variable, alt.value('lightgray'), legend=None),\n",
    "        tooltip=[alt.Tooltip('state:N', title='State'),\n",
    "                 alt.Tooltip('total:Q', title='Total Eligible Voters'),\n",
    "                 alt.Tooltip('total_reg:Q', title='Percent Registered Voters'),\n",
    "                 alt.Tooltip('total_voted:Q', title='Percent Voted')]\n",
    "    ).add_selection(\n",
    "        select_slider\n",
    "    ).transform_filter(\n",
    "        select_slider\n",
    "    ).add_selection(\n",
    "        select_dropdown\n",
    "    ).transform_filter(\n",
    "        select_dropdown\n",
    "    ).add_selection(\n",
    "        highlight\n",
    "    ).transform_filter(\n",
    "        click\n",
    "    ).properties(\n",
    "        width=500,\n",
    "        height=275\n",
    "    )\n",
    "    \n",
    "    \n",
    "    bars = alt.Chart().mark_bar().encode(\n",
    "        x='count()',\n",
    "        y=alt.Y(color_variable, title='Restrictive Laws'),\n",
    "        color=alt.condition(click, color, alt.value('lightgray'))\n",
    "    ).transform_filter(\n",
    "        highlight\n",
    "    ).transform_filter(\n",
    "        select_yr\n",
    "    ).transform_filter(\n",
    "        select_dropdown\n",
    "    ).properties(\n",
    "        width=500,\n",
    "        height=100\n",
    "    ).add_selection(\n",
    "        click\n",
    "    )\n",
    "\n",
    "    return alt.vconcat(scatter, bars, data=df, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "#############\n",
    "# CONSTANTS #\n",
    "#############\n",
    "\n",
    "# filepath expressions for data\n",
    "AGE_FILES = 'clean/*_age.csv'\n",
    "SEXRACE_FILES = 'clean/*_sexrace.csv'\n",
    "LAWS_DATA_PATH = 'clean/supression.csv'\n",
    "\n",
    "'''# useful constants for renaming and removing columns\n",
    "AGE_COLUMN_NAMES = [\n",
    "    'state', 'age_bracket', 'total', 'total_reg', 'percent_reg',\n",
    "    'ci_reg', 'total_voted', 'percent_voted', 'ci_voted', 'yr'\n",
    "]\n",
    "\n",
    "SEX_COLUMN_NAMES = [\n",
    "    'STATE', 'Group', 'Population (18+)', 'Total Citizen', 'Percent Citizen', 'CI Citizen',\n",
    "    'Total Registered', 'Percent Registered (18+)', 'CI Registered', 'Total Voted', 'Percent Voted (18+)',\n",
    "    'CI Voted', 'Year'\n",
    "]'''\n",
    "\n",
    "# desired columns to subset from data\n",
    "KEEP_AGE_COLUMNS = [\n",
    "    'STATE', 'Age', 'Total', 'Total Registered', 'Percent registered (18+)', \n",
    "    'CI Registered', 'Total Voted', 'Percent voted (18+)', 'CI Voted', 'Year'\n",
    "]\n",
    "\n",
    "KEEP_SEX_COLUMNS = [\n",
    "    'STATE', 'Group', 'Population (18+)', 'Total Citizen', 'Percent Citizen', 'CI Citizen',\n",
    "    'Total Registered', 'Percent Registered (18+)', 'CI Registered', 'Total Voted', 'Percent Voted (18+)',\n",
    "    'CI Voted', 'Year'\n",
    "]\n",
    "\n",
    "# desired state labels\n",
    "STATE_NAMES = ['ALABAMA', 'ALASKA', 'ARIZONA', 'ARKANSAS', 'CALIFORNIA', \n",
    "    'COLORADO', 'CONNECTICUT', 'DELAWARE', 'DISTRICT OF COLUMBIA', 'FLORIDA', \n",
    "    'GEORGIA', 'HAWAII', 'IDAHO', 'ILLINOIS', 'INDIANA', 'IOWA', 'KANSAS', \n",
    "    'KENTUCKY', 'LOUISIANA', 'MAINE', 'MARYLAND', 'MASSACHUSETTS', \n",
    "    'MICHIGAN', 'MINNESOTA', 'MISSISSIPPI', 'MISSOURI', 'MONTANA', 'NEBRASKA', \n",
    "    'NEVADA', 'NEW HAMPSHIRE', 'NEW JERSEY', 'NEW MEXICO', 'NEW YORK',\n",
    "    'NORTH CAROLINA', 'NORTH DAKOTA', 'OHIO', 'OKLAHOMA', 'OREGON',\n",
    "    'PENNSYLVANIA', 'RHODE ISLAND', 'SOUTH CAROLINA', 'SOUTH DAKOTA',\n",
    "    'TENNESSEE', 'TEXAS', 'UTAH', 'VERMONT', 'VIRGINIA', 'WASHINGTON',\n",
    "    'WEST VIRGINIA', 'WISCONSIN', 'WYOMING', 'NATIONAL'\n",
    "]\n",
    "\n",
    "# note these integers are related to US Census Bureau ordering \n",
    "STATE_NUMS = [1,  2,  4,  5,  6,  8,  9, 10, 11, 12, 13, 15, 16, 17, 18, 19, \n",
    "    20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37,\n",
    "    38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 0\n",
    "]\n",
    "\n",
    "STATES_TABLE = list(zip(STATE_NAMES, STATE_NUMS))\n",
    "\n",
    "\n",
    "#############\n",
    "# FUNCTIONS #\n",
    "#############\n",
    "\n",
    "\n",
    "def get_age_df(file_path):\n",
    "    '''\n",
    "    Load age data by file name into pd.DataFrame and\n",
    "    return DataFrame object with select columns and cleaned\n",
    "    values.\n",
    "\n",
    "    Note: NaN values are kept for possible use in modeling/viz.\n",
    "\n",
    "    Args:\n",
    "        file_path: str, designating file to retrieve for a given year\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame, processed age data for that year\n",
    "    '''\n",
    "\n",
    "    # load and subset data\n",
    "    df = pd.read_csv(file_path, header=0)\n",
    "    df = df[KEEP_AGE_COLUMNS]\n",
    "\n",
    "    # clean up format and unwanted punctuation\n",
    "    df[\"STATE\"] = df[\"STATE\"].str.upper()\n",
    "    df[\"Year\"] = df[\"Year\"].astype(str)\n",
    "    df['Total'] = df['Total'].replace(',','', regex=True).apply(pd.to_numeric, errors='coerce')\n",
    "    df['Total Registered'] = df['Total Registered'].replace(',','', regex=True).apply(pd.to_numeric, errors='coerce')\n",
    "    df['Total Voted'] = df['Total Voted'].replace(',','', regex=True).apply(pd.to_numeric, errors='coerce')\n",
    "    df['Age'] = df['Age'].map(lambda x: x.lstrip('.'))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_sexrace_df(file_path):\n",
    "    '''\n",
    "    Load sexrace data by file name into pd.DataFrame\n",
    "    and return DataFrame object with select columns and cleaned\n",
    "    values.\n",
    "\n",
    "    Note: NaN values are kept for possible use in modeling/viz.\n",
    "\n",
    "    Args:\n",
    "        file_path: str, file for which to retrieve sexrace data\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame, processed sexrace data for that year\n",
    "    '''\n",
    "\n",
    "    # load and subset data\n",
    "    df = pd.read_csv(file_path, header=0)\n",
    "    df = df[KEEP_SEX_COLUMNS]\n",
    "\n",
    "    # clean up format and unwanted punctuation\n",
    "    df[\"STATE\"] = df[\"STATE\"].str.upper()\n",
    "    df[\"Year\"] = df[\"Year\"].astype(str)\n",
    "    df[\"Total Citizen\"] = df[\"Total Citizen\"].replace(',','', regex=True).apply(pd.to_numeric, errors='coerce')\n",
    "    df[\"Total Registered\"] = df[\"Total Registered\"].replace(',','', regex=True).apply(pd.to_numeric, errors='coerce')\n",
    "    df[\"Total Voted\"] = df[\"Total Voted\"].replace(',','', regex=True).apply(pd.to_numeric, errors='coerce')\n",
    "    df[\"Group\"] = df[\"Group\"].map(lambda x: x.lstrip('.'))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def combine_age_data(file_expression=AGE_FILES, law_filepath=LAWS_DATA_PATH):\n",
    "    '''\n",
    "    Generate all age-related dataframes, combine into one, \n",
    "    and attach legislative data columns.\n",
    "\n",
    "    Args:\n",
    "        file_expression: str, regex to capture desired age files\n",
    "        law_filepath: str, filepath to legislation data\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame, combined age data for all years\n",
    "    '''\n",
    "\n",
    "    # retrieve all relevant file paths\n",
    "    age_file_paths = glob.glob(file_expression)\n",
    "    df_list = []\n",
    "\n",
    "    # generate a dataframe from each file and combine\n",
    "    for age_file in age_file_paths:\n",
    "        print('Reading %s...' % age_file)\n",
    "        df = get_age_df(age_file)\n",
    "        df_list.append(df)\n",
    "    combined = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "\n",
    "    # load legislative data\n",
    "    laws_df = pd.read_csv(law_filepath)\n",
    "    laws_df[\"STATE\"] = laws_df[\"STATE\"].str.upper()\n",
    "\n",
    "    # make nationwide labels consistent\n",
    "    combined[\"STATE\"].loc[combined[\"STATE\"] == 'US'] = 'NATIONAL'\n",
    "    combined[\"STATE\"].loc[combined[\"STATE\"] == 'UNITED STATES'] = 'NATIONAL'\n",
    "    laws_df[\"STATE\"].loc[laws_df[\"STATE\"] == 'US'] = 'NATIONAL'\n",
    "\n",
    "    # attach legislative rating to age data\n",
    "    result_df = combined.merge(laws_df,\n",
    "                               how='outer',\n",
    "                               left_on='STATE',\n",
    "                               right_on='STATE')\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def combine_sexrace_data(file_expression=SEXRACE_FILES, law_filepath=LAWS_DATA_PATH):\n",
    "    '''\n",
    "    Retrieve all sexrace-related data files, combine into one\n",
    "    pd.DataFrame object, and attach legislative data columns.\n",
    "\n",
    "    Args:\n",
    "        file_expression: str, regex to capture desired age files\n",
    "        law_filepath: str, filepath to legislation data\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame, combined sexrace data for all years\n",
    "    '''\n",
    "\n",
    "    # retrieve all relevant file paths\n",
    "    sex_file_paths = glob.glob(file_expression)\n",
    "    df_list = []\n",
    "\n",
    "    # generate a dataframe from each file and combine\n",
    "    for sex_file in sex_file_paths:\n",
    "        print('Reading %s...' % sex_file)\n",
    "        df = get_sexrace_df(sex_file)\n",
    "        df_list.append(df)\n",
    "    combined = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "\n",
    "    # load legislative data\n",
    "    laws_df = pd.read_csv(law_filepath)\n",
    "    laws_df[\"STATE\"] = laws_df[\"STATE\"].str.upper()\n",
    "\n",
    "    # make nationwide labels consistent\n",
    "    combined[\"STATE\"].loc[combined[\"STATE\"] == 'US'] = 'NATIONAL'\n",
    "    combined[\"STATE\"].loc[combined[\"STATE\"] == 'UNITED STATES'] = 'NATIONAL'\n",
    "    laws_df[\"STATE\"].loc[laws_df[\"STATE\"] == 'US'] = 'NATIONAL'\n",
    "\n",
    "    # attach legislative rating to sex/race data\n",
    "    result_df = combined.merge(laws_df,\n",
    "                               how='outer',\n",
    "                               left_on='STATE',\n",
    "                               right_on='STATE')\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "\n",
    "def homogenize_age_data(df):\n",
    "    \"\"\"\n",
    "    Structures the age data by creating the desired age groups\n",
    "    of 'Total','18 to 44', '45 to 65', '65+' into a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df: Dataframe created by function combine_age_data()\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame, age bracket structured data for all years\n",
    "    \"\"\"\n",
    "    # set up a table for the states\n",
    "    df_states = pd.DataFrame(STATES_TABLE, columns=['STATE', 'id'])\n",
    "    df_states[\"STATE\"] = df_states[\"STATE\"].str.upper()\n",
    "\n",
    "    # combine existing age brackets for uniformity\n",
    "    df_65plus = df.loc[(df[\"Age\"] == '65 to 74')\n",
    "        | (df[\"Age\"] == '75+')\n",
    "        | (df[\"Age\"] == '65 to 75')\n",
    "        | (df[\"Age\"] == '65+'),\n",
    "    ]\n",
    "    df_45_64 = df.loc[(df[\"Age\"] == '45 to 64')\n",
    "        | (df[\"Age\"] == '45 to 55')\n",
    "        | (df[\"Age\"] == '55 to 65')\n",
    "        | (df[\"Age\"] == '45 to 65'),\n",
    "    ]\n",
    "    df_18_44 = df.loc[(df[\"Age\"] == '18 to 24')\n",
    "        | (df[\"Age\"] == '18 to 25')\n",
    "        | (df[\"Age\"] == '25 to 44')\n",
    "        | (df[\"Age\"] == '25 to 35')\n",
    "        | (df[\"Age\"] == '35 to 45')\n",
    "        | (df[\"Age\"] == '25 to 45')\n",
    "        | (df[\"Age\"] == '25 to 34')\n",
    "        | (df[\"Age\"] == '35 to 44'),\n",
    "    ]\n",
    "    df_total = df.loc[df[\"Age\"] == 'Total',]\n",
    "\n",
    "    # iteratively group these DFs by state and year\n",
    "    df_list = [df_total, df_18_44, df_45_64, df_65plus]\n",
    "    age_brackets = ['Total','18 to 44', '45 to 65', '65+']\n",
    "    combined = []\n",
    "\n",
    "    for i, df in enumerate(df_list):\n",
    "        df = df.groupby(['STATE', 'Year'], sort=False).sum().reset_index()\n",
    "        df['Age'] = age_brackets[i]\n",
    "        combined.append(df)\n",
    "\n",
    "    # recombine all age bracket DFs\n",
    "    result = pd.concat(combined, axis=0, ignore_index=True)\n",
    "    result.sort_values(['Year', 'STATE'], inplace=True)\n",
    "\n",
    "    # compute voter turnout metric\n",
    "    result['percent_reg'] = result['Total Registered'] / result['Total']\n",
    "    result['percent_voted'] = result['Total Voted'] / result['Total']\n",
    "\n",
    "    # refomatting\n",
    "    result['Year'] = result['Year'].astype(int)\n",
    "    result['STATE'] = result['STATE'].str.upper()\n",
    "\n",
    "    # attach our state labels/IDs\n",
    "    result = df_states.merge(result, how='outer', left_on='STATE', right_on='STATE')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading clean/2000_sexrace.csv...\n",
      "Reading clean/2002_sexrace.csv...\n",
      "Reading clean/2004_sexrace.csv...\n",
      "Reading clean/2006_sexrace.csv...\n",
      "Reading clean/2008_sexrace.csv...\n",
      "Reading clean/2010_sexrace.csv...\n",
      "Reading clean/2012_sexrace.csv...\n",
      "Reading clean/2014_sexrace.csv...\n",
      "Reading clean/2016_sexrace.csv...\n",
      "Reading clean/2018_sexrace.csv...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-d8c289213f97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msexracedf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_sexrace_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msexrace_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhomogenize_sexrace_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msexracedf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-f99e3b29dbb5>\u001b[0m in \u001b[0;36mcombine_sexrace_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m                                \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'outer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                                \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                                right_on='state')\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;31m# make nationwide labels consistent and finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data558/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   7295\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7296\u001b[0m             \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7297\u001b[0;31m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7298\u001b[0m         )\n\u001b[1;32m   7299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data558/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     )\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data558/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data558/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    981\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_rkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data558/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'state'"
     ]
    }
   ],
   "source": [
    "sexracedf = combine_sexrace_data()\n",
    "sexrace_dataframe = homogenize_sexrace_data(sexracedf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading clean/2000_age.csv...\n",
      "Reading clean/2002_age.csv...\n",
      "Reading clean/2004_age.csv...\n",
      "Reading clean/2008_age.csv...\n",
      "Reading clean/2010_age.csv...\n",
      "Reading clean/2012_age.csv...\n",
      "Reading clean/2014_age.csv...\n",
      "Reading clean/2016_age.csv...\n",
      "Reading clean/2018_age.csv...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File clean/suppression.csv does not exist: 'clean/suppression.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-7fe6c4727b90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magedf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_age_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mage_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhomogenize_age_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magedf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-c54b49c49fb4>\u001b[0m in \u001b[0;36mcombine_age_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# concatenate and attach legislative data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0mlaws_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLAWS_DATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0mlaws_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlaws_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data558/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data558/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data558/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data558/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data558/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File clean/suppression.csv does not exist: 'clean/suppression.csv'"
     ]
    }
   ],
   "source": [
    "agedf = combine_age_data()\n",
    "age_dataframe = homogenize_age_data(agedf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sexrace_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>id</th>\n",
       "      <th>Year</th>\n",
       "      <th>Total</th>\n",
       "      <th>Total Registered</th>\n",
       "      <th>Total Voted</th>\n",
       "      <th>restrictive_id_laws</th>\n",
       "      <th>felony_disenfranchisement</th>\n",
       "      <th>Age</th>\n",
       "      <th>percent_reg</th>\n",
       "      <th>percent_voted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>3233.0</td>\n",
       "      <td>2411</td>\n",
       "      <td>1953</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Total</td>\n",
       "      <td>0.745747</td>\n",
       "      <td>0.604083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>1676.0</td>\n",
       "      <td>1165</td>\n",
       "      <td>927</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18 to 44</td>\n",
       "      <td>0.695107</td>\n",
       "      <td>0.553103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>834</td>\n",
       "      <td>701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>45 to 65</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.663826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>501.0</td>\n",
       "      <td>413</td>\n",
       "      <td>325</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>65+</td>\n",
       "      <td>0.824351</td>\n",
       "      <td>0.648703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "      <td>3215.0</td>\n",
       "      <td>2347</td>\n",
       "      <td>1585</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Total</td>\n",
       "      <td>0.730016</td>\n",
       "      <td>0.493002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>NATIONAL</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>48684.0</td>\n",
       "      <td>36667</td>\n",
       "      <td>33314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65+</td>\n",
       "      <td>0.753163</td>\n",
       "      <td>0.684291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>NATIONAL</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>249748.0</td>\n",
       "      <td>153066</td>\n",
       "      <td>122281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Total</td>\n",
       "      <td>0.612882</td>\n",
       "      <td>0.489618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>NATIONAL</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>114546.0</td>\n",
       "      <td>59966</td>\n",
       "      <td>43312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18 to 44</td>\n",
       "      <td>0.523510</td>\n",
       "      <td>0.378119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>NATIONAL</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>83277.0</td>\n",
       "      <td>55032</td>\n",
       "      <td>45829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45 to 65</td>\n",
       "      <td>0.660831</td>\n",
       "      <td>0.550320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>NATIONAL</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>51925.0</td>\n",
       "      <td>38068</td>\n",
       "      <td>33139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65+</td>\n",
       "      <td>0.733134</td>\n",
       "      <td>0.638209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1851 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         STATE  id  Year     Total  Total Registered  Total Voted  \\\n",
       "0      ALABAMA   1  2000    3233.0              2411         1953   \n",
       "1      ALABAMA   1  2000    1676.0              1165          927   \n",
       "2      ALABAMA   1  2000    1056.0               834          701   \n",
       "3      ALABAMA   1  2000     501.0               413          325   \n",
       "4      ALABAMA   1  2002    3215.0              2347         1585   \n",
       "...        ...  ..   ...       ...               ...          ...   \n",
       "1846  NATIONAL   0  2016   48684.0             36667        33314   \n",
       "1847  NATIONAL   0  2018  249748.0            153066       122281   \n",
       "1848  NATIONAL   0  2018  114546.0             59966        43312   \n",
       "1849  NATIONAL   0  2018   83277.0             55032        45829   \n",
       "1850  NATIONAL   0  2018   51925.0             38068        33139   \n",
       "\n",
       "      restrictive_id_laws  felony_disenfranchisement       Age  percent_reg  \\\n",
       "0                     1.0                        4.0     Total     0.745747   \n",
       "1                     2.0                        8.0  18 to 44     0.695107   \n",
       "2                     1.0                        4.0  45 to 65     0.789773   \n",
       "3                     2.0                        8.0       65+     0.824351   \n",
       "4                     1.0                        4.0     Total     0.730016   \n",
       "...                   ...                        ...       ...          ...   \n",
       "1846                  0.0                        0.0       65+     0.753163   \n",
       "1847                  0.0                        0.0     Total     0.612882   \n",
       "1848                  0.0                        0.0  18 to 44     0.523510   \n",
       "1849                  0.0                        0.0  45 to 65     0.660831   \n",
       "1850                  0.0                        0.0       65+     0.733134   \n",
       "\n",
       "      percent_voted  \n",
       "0          0.604083  \n",
       "1          0.553103  \n",
       "2          0.663826  \n",
       "3          0.648703  \n",
       "4          0.493002  \n",
       "...             ...  \n",
       "1846       0.684291  \n",
       "1847       0.489618  \n",
       "1848       0.378119  \n",
       "1849       0.550320  \n",
       "1850       0.638209  \n",
       "\n",
       "[1851 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_map_chart(sexrace_dataframe, map_value='percent_voted',\n",
    "             map_title='Percent Voted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scatter_turnout(df_in=sexrace_dataframe,x_value='percent_reg:Q',y_value='percent_voted:Q',\n",
    "               color_variable='restrictive_id_laws:N',title='',\n",
    "               y_title='Percent Voted', x_title='Percent Registered', select_slider=select_yr,\n",
    "                select_dropdown=cat_select_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['state', 'group', 'yr'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-29bb1ed52dbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m map1 = us_map_chart(age_dataframe, map_value='percent_voted',\n\u001b[0;32m----> 2\u001b[0;31m              map_title='Percent Voted')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-2156cfa5bf3b>\u001b[0m in \u001b[0;36mus_map_chart\u001b[0;34m(df_in, map_value, map_title, selection_link)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0myear_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0myear\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2019\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     df_pivot = df[columns_keep].pivot_table(index=['id','state','group'], \n\u001b[0m\u001b[1;32m     38\u001b[0m                                                                              columns='yr', values=map_value)\n\u001b[1;32m     39\u001b[0m     \u001b[0mmapdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_pivot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data558/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2804\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2806\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data558/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m         )\n\u001b[1;32m   1555\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data558/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1644\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"loc\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1645\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['state', 'group', 'yr'] not in index\""
     ]
    }
   ],
   "source": [
    "map1 = us_map_chart(age_dataframe, map_value='percent_voted',\n",
    "             map_title='Percent Voted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map2 = us_map_chart(age_dataframe, map_value='percent_reg',\n",
    "             map_title='Percent Registered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map1 & map2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnout = scatter_turnout(df_in=age_dataframe,x_value='percent_reg:Q',y_value='percent_voted:Q',\n",
    "               color_variable='restrictive_id_laws:N',title='',\n",
    "               y_title='Percent Voted', x_title='Percent Registered', select_slider=select_yr,\n",
    "                         select_dropdown=cat_select_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.hconcat(turnout, (map1 & map2), title='Voter Turnout by Age Group').save('Age_Turnout_Prototype.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_variable='restrictive_id_laws:N'\n",
    "\n",
    "highlight2 = alt.selection_interval(encodings=['x'])\n",
    "color = alt.Color(color_variable)\n",
    "click = alt.selection_multi(encodings=['color'])\n",
    "legend_select = alt.selection_multi(fields=['total'], bind='legend')\n",
    "\n",
    "\n",
    "alt.Chart(sexrace_dataframe).mark_point().encode(\n",
    "        x=alt.X('percent_reg:Q', title='',\n",
    "               scale=alt.Scale(domain=[.15, .96])),\n",
    "        y=alt.Y('percent_voted:Q', title='',\n",
    "               scale=alt.Scale(domain=[.15, .93])),\n",
    "        size=alt.Size('total:Q', title='Total Eligible Voters'),\n",
    "        color='restrictive_id_laws:N',\n",
    "        opacity=alt.condition(legend_select, alt.value(2), alt.value(0.1)),\n",
    "        tooltip=[alt.Tooltip('state:N', title='State'),\n",
    "                 alt.Tooltip('total:Q', title='Total Eligible Voters'),\n",
    "                 alt.Tooltip('total_reg:Q', title='Percent Registered Voters'),\n",
    "                 alt.Tooltip('total_voted:Q', title='Percent Voted')]\n",
    "    ).add_selection(\n",
    "        select_yr\n",
    "    ).transform_filter(\n",
    "        select_yr\n",
    "    ).properties(\n",
    "        width=500,\n",
    "        height=275\n",
    "    ).add_selection(\n",
    "        legend_select\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_geo = create_geodataframe(age_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = alt.topo_feature(data.us_10m.url, feature='states')\n",
    "background = alt.Chart(states).mark_geoshape(\n",
    "    fill='lightgray',\n",
    "    stroke='white'\n",
    ").properties(\n",
    "    width=500,\n",
    "    height=300\n",
    ").project('albersUsa')\n",
    "\n",
    "points = alt.Chart(age_geo).mark_circle(\n",
    "    size=10,\n",
    ").encode(\n",
    "    longitude='centroid_lon:Q',\n",
    "    latitude='centroid_lat:Q',\n",
    "    size=alt.Size('total_voted:Q', scale=alt.Scale(type='linear')),\n",
    "    tooltip=['state:N','percent_voted:Q']\n",
    ").project('albersUsa').add_selection(\n",
    "        select_yr\n",
    "    ).transform_filter(\n",
    "        select_yr\n",
    "    )\n",
    "\n",
    "background + points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(states).mark_geoshape().encode(\n",
    "    color='restrictive_id_laws:N'\n",
    ").transform_lookup(\n",
    "    lookup='id',\n",
    "    from_=alt.LookupData(age_geo, 'id', ['restrictive_id_laws'])\n",
    ").project(\n",
    "    type='albersUsa'\n",
    ").properties(\n",
    "    width=500,\n",
    "    height=300\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
